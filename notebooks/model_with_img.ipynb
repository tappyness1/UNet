{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neoce\\miniconda3\\envs\\pytorch-cpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.model import UNet\n",
    "from src.dataset import get_load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = UNet(num_classes=20)\n",
    "train, test = get_load_data(root = \"../../data\", dataset = \"VOCSegmentation\", download = False)  \n",
    "img, smnt = train[0] \n",
    "img = img.reshape(1, 3, 572, 572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smnt = smnt.resize((388, 388))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "smnt = torch.tensor(np.asarray(smnt), dtype = torch.float32).reshape(1, 1, 388, 388)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAGECAMAAAABY6fhAAADAFBMVEUAAACAAAAAgACAgAAAAICAAIAAgICAgIBAAADAAABAgADAgABAAIDAAIBAgIDAgIAAQACAQAAAwACAwAAAQICAQIAAwICAwIBAQADAQABAwADAwABAQIDAQIBAwIDAwIAAAECAAEAAgECAgEAAAMCAAMAAgMCAgMBAAEDAAEBAgEDAgEBAAMDAAMBAgMDAgMAAQECAQEAAwECAwEAAQMCAQMAAwMCAwMBAQEDAQEBAwEDAwEBAQMDAQMBAwMDAwMAgAACgAAAggACggAAgAICgAIAggICggIBgAADgAABggADggABgAIDgAIBggIDggIAgQACgQAAgwACgwAAgQICgQIAgwICgwIBgQADgQABgwADgwABgQIDgQIBgwIDgwIAgAECgAEAggECggEAgAMCgAMAggMCggMBgAEDgAEBggEDggEBgAMDgAMBggMDggMAgQECgQEAgwECgwEAgQMCgQMAgwMCgwMBgQEDgQEBgwEDgwEBgQMDgQMBgwMDgwMAAIACAIAAAoACAoAAAIICAIIAAoICAoIBAIADAIABAoADAoABAIIDAIIBAoIDAoIAAYACAYAAA4ACA4AAAYICAYIAA4ICA4IBAYADAYABA4ADA4ABAYIDAYIBA4IDA4IAAIECAIEAAoECAoEAAIMCAIMAAoMCAoMBAIEDAIEBAoEDAoEBAIMDAIMBAoMDAoMAAYECAYEAA4ECA4EAAYMCAYMAA4MCA4MBAYEDAYEBA4EDA4EBAYMDAYMBA4MDA4MAgIACgIAAgoACgoAAgIICgIIAgoICgoIBgIADgIABgoADgoABgIIDgIIBgoIDgoIAgYACgYAAg4ACg4AAgYICgYIAg4ICg4IBgYADgYABg4ADg4ABgYIDgYIBg4IDg4IAgIECgIEAgoECgoEAgIMCgIMAgoMCgoMBgIEDgIEBgoEDgoEBgIMDgIMBgoMDgoMAgYECgYEAg4ECg4EAgYMCgYMAg4MCg4MBgYEDgYEBg4EDg4EBgYMDgYMBg4MDg4MCa7rFGAAAMYUlEQVR4Ae2dC5KkKhBFZ1bg/lc7QyYgoIBWl5LYHiOmTH75OResqu6O9/784YIABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAgZcS+CfXS2ufpmwVARVM9fAacBYQwZSAffB4EHge2WmhGvz9Kze7JN4eGREm2AEiwl9Ogq0SXgNVwTaRF0cPB4H3BMs9gAiW9H1s0UDeEjgJdlqsGogIdmm8OnLSABHMNgIimKFPgUUEeUNwl7NSP9ZAAogwEHYrFCK0yAzsR4SBsKuhRAF3rW8JvCdUMd3T6dmvr4hwD+a+1xW/NxChj+vq0Q1+bXoN+IR6NevMXw170Rc0QIS73hEL2pVGFEDubjjT7oXmXeVXuBddiBA2W0Hl2g1YuM4bOfxou/FO9HV1Z84zh9bKdsYl9ey8uo6IfH93g+2ouav2rEeO5KWV9iXllC59aw8/9rjxdtTcVXvW40bysir2BfVEr5Fy/y6zW0Gjp3RvzXxSf6qmZX1fjffcJ59GdXYjaC3HxtQnddfKKvu+r0b8JcgHlgYvYkqP79Cx4CvY61ix5GGNVEvL+r4g8XyAPg1rGkVM6fEdOoYIBZ2zDWGXKPct5Vw4DuTTLTpYe/6sljOKtQ9p5PnX7a8LEbcR3ME9ZJCH3CS1cbAZlWa++CF2pYpN19eFiL8Nu1YzhM5DbrLZrNyMSjNf/Ay7UsS26+tCxOGGXb0ZI+cRY1+871bGgXTPlz/BTpm3ra/rcK536PYdKYE8oO+VH+nptV/m/1wvjvt77uABdpm8tG5IWtzW6K19MmG9ygSke51XN8op6qf0MXtLUy5ebsi4pFQh2UngcK0/Ccmp+rqhiKe7bIBct3iuwbbWxtoEXUXImt7Z1g1t/RjvOSkiNTO6npu+7mBl0zLShfnvb/nAkiU7P3QoXwdO7+5FGIrtWcbeGicd89P6r9GZzHKLar5e3hdRRtyBFCKM3BcRfrxHEdYj0dq5foFM717OTxBUp7lVI6t7SqxIP9wjqrW7UYeOd/FXB92yhsNXd6+0vYEIJrthVeFP/Ki09jijlZLMqe71fmfHYyvSS/oFqOLW+/pBKXRWIchYH3d91C2r+qMzERC2esVfA6ShwtI5dczdXllXOKKxJ6BwlVSw9lO0R0e7uOuD6rrhk+5AIKA/2q3faHDkGy3CU+gIhIhQ3+r9Xll35Jtx/wHpCNRHGuR6ocG5LSaAEeEcq5/MUr5HL2cci4/+cycbzSc7+4z/7hzxt17dmTMOrpmfMzoliIMMc8/0scIMaXTcNoe8k+prc82kA9Ui2p2dKmRRj3w25v0jQqDZxt0bqUrxqQaqWIhSddjo7CX2A3eNKAO7TxR0PMXnK/Oyzd4zdy7PVbxb1u4453CSWVJGD5cfaxfrR6QYtY5dyYy9u5LGfvxETwotk0uHk7ck4ZR+y5JZvUuK1PGWg7J/76qktB8/0ZNCyOTS4eQtl2/K/oTVp3HCgZuiPoJq3l+A1HdeGW3EczMnx16mJ5U1Sul0V3icdtRY+1F3JzU3JK7KKidvScL9kmqjsqpy1abu+irrPu7aOS06xN3k2Mv0Qv1FER82EsJzC9P8z61OhNJZWeXsrZB7p7rjoVj/8UydEae37ycdVT5mBZ+zU9/m10axjpxl8sE873tL8ayDNbOWsS1y9narjqz/LJsP5nnviBB3R0b7yPyA8k1TjzL047G0R93PlSazbmJ71m030UchryTbLa47eBZfnPeVjLtMKqU8t2tX3emOCPfsHRF+tEvO6XFWhIN554I97MvYj7C3FnUJFX9l3UbdPAld52mwldtr+hOKioUIo/ZBBX7qam//bMRNDy1vpeXnrFGVPihOAS5D3TGjBvJFzU0rPBw3HsRmfKqCr0M+G4rT/Iod9vGp/56IiDCDludPgh4FfwKKp9EMVTw8h7MiePrh9YG/BZtaJkSYQB5EeLYIz/qF8ASsmymcPQnFF4P4xtz0ysBHBBDhI1z3TD4rgpsnjx+5yU+b3IvvuCerl3kVqGeuwDybjgiXbZWMaleLgFyne9kQAREuIzCBo5MnwU3TT6Q6nZNwsXDnRBANEOFi9MndeRF0jU737+VBluQK66cEEOGn5C5cd0oENyn8jEKn+zVr34XZvNSVB9r9dOp/YuH5IMId+wQR7qD6oU8nwuFXZpkT3OpsvyR1fhiS6VsCDuUZEeIyne6XuNfYy/1LAsciCPgYRGy9+AFeRHLF3SHtvy0XuIMEbo1YV8THhyMgMLsqyISEW1vxBYAXERCghyKkWJG/3FMv1ncEhCYifMfw+9UHKshwvue1ue38PouXe1CgrbOgg7kGAZZK8XJwl5YvQLsiXBoNZ1UCiFDFMrZTRGgcBR0am81boynqmgxoMHBLKOzd24LXZmAa7w6FCDPov1fBH4PiG8IMif7qHHYqBBF+ddGzFYcIMyiyVYGTYKHKRgVpWqTx8piCPX1MRQST7YAIJtjLoHsReB6VhAa0ShHyv/gaEJwQnsBGBH6Tb7ExEMGC+ibmVgQ5CpspNO8m4JinT6jOElHujon/DQFE2AAZ2ZQdL1t+KwKPo3EqqAaighjb59G4NF4dKWgQbrkI0vVqNOOKR4RxrJuRmiLoQHMZA1cScKyXJSmxPo/Q4ErKB74Q4QDQiGEVIZ2F4iSMiE8MRyCJ4JVQFdxHVdcPn1EEVhEWd7mGfFWQV/dvVArEcbA9fkSw2wyFCItrpcsuqcGRpeTBIctwLr6cgSW8JgmM8yqzvLUVa741SNe5ZFAXobvsNw0igr2aUQPDJ5JPQT4YufOw5uMMezpjMshqHhOwEsXnkPGvzPnVXYgwgbwiQtyDVunoRpB35kWt1zyFVt5S9lr+2jvWkBQ0iUWyeZ8G+gtFEUHrH8t+jebAawqmSazZGBiy9ZSAGAbxJWRM4a0iCPq0C81FWFw6RknYhRUNEMGOv0TeaGC1CdNGWJxpi2R8dEQYz3wXUUQI7wiL2LsJYzrKLMbEnCdKVv3ibCsVXOBsK8yDZ0wmWfWLsxFhDPYyisMet6DlZ/QsDbONUIIZ2cqqR4SR4PNYiJDTMLIRwQh8HrYQYXGtfHCcnaVhlsO4areRsurdG7QZgCwNsxy2aMa1s+oRYRz2MtJOBJvnUZbGO0/CDF8UECF9W1scDJOjgAiIUD6ix7eyPejfmTkJ1iIsThMLFSRsOJA2CYwHn0dM1SsEoZEPD7JTFkYJDKqzESaVjwgNRPd3b0RYXPv+oLsIKQtnWSSwy2hoRyrfP5NtGKQsnIUINgwQIXws4SQMfQTlwdIeRIScy1AbEYbirgdDhDqXob1OhH/Zm4I0h8b3wVISRgkY1JyFlKKTCtrKRkeZKQfJYFTUeeJI1etRsEKQcrDKwFYQqRoRbDXwfx0fVXCCmKSzbgTZEiYZGAeVusNhEMMkG03AHUhJwCYDk7JTUC3cP5HMELjATgFEWCwR5CKk7fEmS4+C02ARw6ZwFzieBJsE7KMKfEQw1gERjAXQ8OkkGGWjCcgTyep5aFR3HhYRchpGNiIYgc/DIkJOw8hGBCPweVhEyGkY2YhgBD4Piwg5DSN7EhFcGnxPsEPgIi/un1xG+9A+rKs9/OzIKBdJwP2TyygD+7Cu9iCCEQPFry/2MKwyQAQr8llcRMhgWJnyIHDPI7kZpSCh5TIKP0NYKd9WBP0vIs6AwjAHexEMi58lNCJMoAQiIMIEBCZIgZOACBMQmCAFdxLCD28mSOatKYgIer0VwAx1Rw3e/I3VXgcOgr0G4X+kMEMir87BnYVX1z9F8YgwhQwkAQEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAgd9H4D80r3lQkD5+1gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=P size=388x388>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = unet_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_argmax = pred.argmax(dim = 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_argmax = pred_argmax.dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"softmax_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_argmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmnt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(loss)\n",
      "File \u001b[1;32mc:\\Users\\neoce\\miniconda3\\envs\\pytorch-cpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\neoce\\miniconda3\\envs\\pytorch-cpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neoce\\miniconda3\\envs\\pytorch-cpu\\lib\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"softmax_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss(reduction='none')(pred_argmax, smnt)\n",
    "loss = torch.mean(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
